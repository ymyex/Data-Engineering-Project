{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0326ad",
   "metadata": {},
   "source": [
    "# ETL Pipeline: Laptop E-Commerce Analysis\n",
    "\n",
    "**Course**: TTTC3213 Data Engineering  \n",
    "**Goal**: Analysis of Laptop Price Distribution and Brand Popularity  \n",
    "**Source**: https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops\n",
    "\n",
    "---\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb951ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(\"âœ“ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebb171",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. LaptopETL Class\n",
    "Contains all ETL methods: extract, clean, transform, visualize, load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0043ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaptopETL:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.raw_data = []\n",
    "        self.df_raw = None\n",
    "        self.df_clean = None\n",
    "        self.output_dir = \"output\"\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "    \n",
    "    def extract_data(self):\n",
    "        \"\"\"\n",
    "        EXTRACTION PHASE\n",
    "        Scrape laptop data from the e-commerce website\n",
    "        Attributes collected: name, price, description, rating, reviews, image\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"EXTRACTION PHASE: Scraping laptop data from website\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # Send GET request to the website\n",
    "            response = requests.get(self.url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse HTML content\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find all laptop product cards\n",
    "            products = soup.find_all('div', class_='card-body')\n",
    "            \n",
    "            print(f\"\\nFound {len(products)} laptop products\")\n",
    "            \n",
    "            # Extract data from each product\n",
    "            for idx, product in enumerate(products, 1):\n",
    "                try:\n",
    "                    # Extract product name\n",
    "                    name_tag = product.find('a', class_='title')\n",
    "                    name = name_tag.get('title', '') if name_tag else ''\n",
    "                    \n",
    "                    # Extract price\n",
    "                    price_tag = product.find('h4', class_='price')\n",
    "                    price = price_tag.text.strip() if price_tag else ''\n",
    "                    \n",
    "                    # Extract description\n",
    "                    desc_tag = product.find('p', class_='description')\n",
    "                    description = desc_tag.text.strip() if desc_tag else ''\n",
    "                    \n",
    "                    # Extract rating\n",
    "                    rating_tag = product.find('p', {'data-rating': True})\n",
    "                    rating = rating_tag.get('data-rating', '0') if rating_tag else '0'\n",
    "                    \n",
    "                    # Extract number of reviews\n",
    "                    reviews_tag = product.find('p', class_='review-count')\n",
    "                    reviews = reviews_tag.text.strip() if reviews_tag else '0 reviews'\n",
    "                    \n",
    "                    # Store extracted data\n",
    "                    laptop_data = {\n",
    "                        'product_name': name,\n",
    "                        'price': price,\n",
    "                        'description': description,\n",
    "                        'rating': rating,\n",
    "                        'reviews': reviews,\n",
    "                        'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    }\n",
    "                    \n",
    "                    self.raw_data.append(laptop_data)\n",
    "                    \n",
    "                    if idx <= 5:  # Print first 5 for verification\n",
    "                        print(f\"\\nProduct {idx}:\")\n",
    "                        print(f\"  Name: {name[:50]}...\")\n",
    "                        print(f\"  Price: {price}\")\n",
    "                        print(f\"  Rating: {rating}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting product {idx}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            self.df_raw = pd.DataFrame(self.raw_data)\n",
    "            print(f\"\\nâœ“ Successfully extracted {len(self.df_raw)} records\")\n",
    "            print(f\"âœ“ Attributes collected: {list(self.df_raw.columns)}\")\n",
    "            \n",
    "            # Save raw data\n",
    "            self.df_raw.to_csv(f\"{self.output_dir}/raw_data.csv\", index=False)\n",
    "            print(f\"âœ“ Raw data saved to {self.output_dir}/raw_data.csv\")\n",
    "            \n",
    "            return self.df_raw\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"âœ— Error fetching data from website: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def clean_and_transform_data(self):\n",
    "        \"\"\"\n",
    "        TRANSFORMATION PHASE\n",
    "        Clean and transform the raw data\n",
    "        Operations: \n",
    "        1. Remove duplicates\n",
    "        2. Handle missing values\n",
    "        3. Standardize price format\n",
    "        4. Extract brand from product name\n",
    "        5. Normalize ratings\n",
    "        6. Clean review counts\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRANSFORMATION PHASE: Cleaning and transforming data\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if self.df_raw is None or self.df_raw.empty:\n",
    "            print(\"âœ— No raw data available to clean\")\n",
    "            return None\n",
    "        \n",
    "        # Create a copy for cleaning\n",
    "        self.df_clean = self.df_raw.copy()\n",
    "        \n",
    "        print(f\"\\nInitial dataset shape: {self.df_clean.shape}\")\n",
    "        print(f\"Initial missing values:\\n{self.df_clean.isnull().sum()}\")\n",
    "        \n",
    "        # ===== CLEANING OPERATION 1: Remove Duplicates =====\n",
    "        print(\"\\n1. Removing duplicate records...\")\n",
    "        initial_rows = len(self.df_clean)\n",
    "        self.df_clean = self.df_clean.drop_duplicates(subset=['product_name', 'price'])\n",
    "        duplicates_removed = initial_rows - len(self.df_clean)\n",
    "        print(f\"   âœ“ Removed {duplicates_removed} duplicate records\")\n",
    "        \n",
    "        # ===== CLEANING OPERATION 2: Handle Missing Values =====\n",
    "        print(\"\\n2. Handling missing values...\")\n",
    "        # Fill missing descriptions with 'No description available'\n",
    "        self.df_clean['description'] = self.df_clean['description'].fillna('No description available')\n",
    "        # Fill missing ratings with median rating\n",
    "        self.df_clean['rating'] = self.df_clean['rating'].replace('', '0')\n",
    "        print(f\"   âœ“ Filled missing values\")\n",
    "        \n",
    "        # ===== CLEANING OPERATION 3: Standardize Price Format =====\n",
    "        print(\"\\n3. Standardizing price format...\")\n",
    "        def clean_price(price_str):\n",
    "            \"\"\"Extract numeric price from string like '$1234.56'\"\"\"\n",
    "            if pd.isna(price_str) or price_str == '':\n",
    "                return 0.0\n",
    "            # Remove currency symbol and convert to float\n",
    "            price_clean = re.sub(r'[^\\d.]', '', str(price_str))\n",
    "            try:\n",
    "                return float(price_clean)\n",
    "            except ValueError:\n",
    "                return 0.0\n",
    "        \n",
    "        self.df_clean['price_numeric'] = self.df_clean['price'].apply(clean_price)\n",
    "        print(f\"   âœ“ Converted prices to numeric format\")\n",
    "        print(f\"   Price range: ${self.df_clean['price_numeric'].min():.2f} - ${self.df_clean['price_numeric'].max():.2f}\")\n",
    "        \n",
    "        # ===== CLEANING OPERATION 4: Extract Brand from Product Name =====\n",
    "        print(\"\\n4. Extracting brand information...\")\n",
    "        def extract_brand(product_name):\n",
    "            \"\"\"Extract brand name (first word) from product name\"\"\"\n",
    "            if pd.isna(product_name) or product_name == '':\n",
    "                return 'Unknown'\n",
    "            # Common laptop brands\n",
    "            brands = ['Lenovo', 'Asus', 'Acer', 'Dell', 'HP', 'MSI', 'Apple', \n",
    "                     'Toshiba', 'Samsung', 'Sony', 'Gateway']\n",
    "            \n",
    "            # Check if any brand appears in the product name\n",
    "            for brand in brands:\n",
    "                if brand.lower() in product_name.lower():\n",
    "                    return brand\n",
    "            \n",
    "            # If no known brand found, use first word\n",
    "            words = product_name.split()\n",
    "            return words[0] if words else 'Unknown'\n",
    "        \n",
    "        self.df_clean['brand'] = self.df_clean['product_name'].apply(extract_brand)\n",
    "        print(f\"   âœ“ Extracted {self.df_clean['brand'].nunique()} unique brands\")\n",
    "        print(f\"   Brands found: {', '.join(self.df_clean['brand'].unique())}\")\n",
    "        \n",
    "        # ===== CLEANING OPERATION 5: Normalize Ratings =====\n",
    "        print(\"\\n5. Normalizing rating values...\")\n",
    "        self.df_clean['rating_numeric'] = pd.to_numeric(self.df_clean['rating'], errors='coerce').fillna(0)\n",
    "        print(f\"   âœ“ Converted ratings to numeric format\")\n",
    "        print(f\"   Rating range: {self.df_clean['rating_numeric'].min():.1f} - {self.df_clean['rating_numeric'].max():.1f}\")\n",
    "        \n",
    "        # ===== CLEANING OPERATION 6: Clean Review Counts =====\n",
    "        print(\"\\n6. Cleaning review counts...\")\n",
    "        def clean_reviews(review_str):\n",
    "            \"\"\"Extract numeric review count from string like '23 reviews'\"\"\"\n",
    "            if pd.isna(review_str) or review_str == '':\n",
    "                return 0\n",
    "            # Extract number from string\n",
    "            numbers = re.findall(r'\\d+', str(review_str))\n",
    "            return int(numbers[0]) if numbers else 0\n",
    "        \n",
    "        self.df_clean['review_count'] = self.df_clean['reviews'].apply(clean_reviews)\n",
    "        print(f\"   âœ“ Extracted numeric review counts\")\n",
    "        print(f\"   Total reviews: {self.df_clean['review_count'].sum()}\")\n",
    "        \n",
    "        # Create final clean dataset with selected columns\n",
    "        self.df_clean = self.df_clean[[\n",
    "            'product_name', 'brand', 'price_numeric', 'rating_numeric', \n",
    "            'review_count', 'description', 'extraction_date'\n",
    "        ]]\n",
    "        \n",
    "        # Rename columns for clarity\n",
    "        self.df_clean.columns = [\n",
    "            'Product Name', 'Brand', 'Price (USD)', 'Rating', \n",
    "            'Review Count', 'Description', 'Extraction Date'\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nâœ“ Data cleaning completed!\")\n",
    "        print(f\"Final dataset shape: {self.df_clean.shape}\")\n",
    "        print(f\"\\nCleaned Dataset Summary:\")\n",
    "        print(self.df_clean.describe())\n",
    "        \n",
    "        return self.df_clean\n",
    "    \n",
    "    def visualize_cleaning_process(self):\n",
    "        \"\"\"\n",
    "        Create before/after visualizations to show data cleaning impact\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"VISUALIZATION: Creating before/after comparison charts\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Data Cleaning Process: Before vs After', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Data completeness comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        missing_before = self.df_raw.isnull().sum().sum()\n",
    "        missing_after = self.df_clean.isnull().sum().sum()\n",
    "        \n",
    "        bars = ax1.bar(['Before Cleaning', 'After Cleaning'], \n",
    "                       [missing_before, missing_after],\n",
    "                       color=['#ff6b6b', '#51cf66'])\n",
    "        ax1.set_ylabel('Number of Missing Values', fontsize=10)\n",
    "        ax1.set_title('Missing Values Comparison', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylim(0, max(missing_before, missing_after) * 1.2)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # 2. Record count comparison\n",
    "        ax2 = axes[0, 1]\n",
    "        bars = ax2.bar(['Raw Data', 'After Deduplication'], \n",
    "                       [len(self.df_raw), len(self.df_clean)],\n",
    "                       color=['#4c6ef5', '#51cf66'])\n",
    "        ax2.set_ylabel('Number of Records', fontsize=10)\n",
    "        ax2.set_title('Data Deduplication Impact', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # 3. Price data quality\n",
    "        ax3 = axes[1, 0]\n",
    "        \n",
    "        # Count valid prices before and after\n",
    "        raw_prices = self.df_raw['price'].apply(lambda x: bool(re.search(r'\\d', str(x))))\n",
    "        valid_before = raw_prices.sum()\n",
    "        valid_after = (self.df_clean['Price (USD)'] > 0).sum()\n",
    "        \n",
    "        bars = ax3.bar(['Before (Text)', 'After (Numeric)'], \n",
    "                       [valid_before, valid_after],\n",
    "                       color=['#ffd43b', '#51cf66'])\n",
    "        ax3.set_ylabel('Valid Price Records', fontsize=10)\n",
    "        ax3.set_title('Price Standardization', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # 4. New features added\n",
    "        ax4 = axes[1, 1]\n",
    "        original_features = len(self.df_raw.columns)\n",
    "        final_features = len(self.df_clean.columns)\n",
    "        \n",
    "        categories = ['Original\\nAttributes', 'After\\nTransformation']\n",
    "        values = [original_features, final_features]\n",
    "        bars = ax4.bar(categories, values, color=['#868e96', '#51cf66'])\n",
    "        ax4.set_ylabel('Number of Attributes', fontsize=10)\n",
    "        ax4.set_title('Feature Engineering', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}/data_cleaning_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ“ Saved cleaning comparison visualization to {self.output_dir}/data_cleaning_comparison.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        LOADING PHASE\n",
    "        Save cleaned data to CSV file\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"LOADING PHASE: Saving cleaned data\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if self.df_clean is None or self.df_clean.empty:\n",
    "            print(\"âœ— No cleaned data available to save\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Save to CSV\n",
    "            output_file = f\"{self.output_dir}/laptops_clean_data.csv\"\n",
    "            self.df_clean.to_csv(output_file, index=False)\n",
    "            \n",
    "            print(f\"âœ“ Cleaned data saved successfully!\")\n",
    "            print(f\"âœ“ File: {output_file}\")\n",
    "            print(f\"âœ“ Records: {len(self.df_clean)}\")\n",
    "            print(f\"âœ“ Columns: {list(self.df_clean.columns)}\")\n",
    "            print(f\"âœ“ File size: {os.path.getsize(output_file) / 1024:.2f} KB\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error saving data: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def generate_summary_statistics(self):\n",
    "        \"\"\"Generate and display summary statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Dataset Overview:\")\n",
    "        print(f\"   Total Products: {len(self.df_clean)}\")\n",
    "        print(f\"   Unique Brands: {self.df_clean['Brand'].nunique()}\")\n",
    "        print(f\"   Price Range: ${self.df_clean['Price (USD)'].min():.2f} - ${self.df_clean['Price (USD)'].max():.2f}\")\n",
    "        print(f\"   Average Price: ${self.df_clean['Price (USD)'].mean():.2f}\")\n",
    "        print(f\"   Average Rating: {self.df_clean['Rating'].mean():.2f}/5\")\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ Brand Distribution:\")\n",
    "        brand_counts = self.df_clean['Brand'].value_counts()\n",
    "        for brand, count in brand_counts.items():\n",
    "            print(f\"   {brand}: {count} products ({count/len(self.df_clean)*100:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nðŸ’° Price Statistics by Brand:\")\n",
    "        price_by_brand = self.df_clean.groupby('Brand')['Price (USD)'].agg(['mean', 'min', 'max'])\n",
    "        print(price_by_brand.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa2c0d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Execute ETL\n",
    "### 3.1 Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb69bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops\"\n",
    "etl = LaptopETL(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a12ff7",
   "metadata": {},
   "source": [
    "### 3.2 Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42125c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTION PHASE: Scraping laptop data from website\n",
      "============================================================\n",
      "\n",
      "Found 117 laptop products\n",
      "\n",
      "Product 1:\n",
      "  Name: Asus VivoBook X441NA-GA190...\n",
      "  Price: $295.99\n",
      "  Rating: 3\n",
      "\n",
      "Product 2:\n",
      "  Name: Prestigio SmartBook 133S Dark Grey...\n",
      "  Price: $299\n",
      "  Rating: 2\n",
      "\n",
      "Product 3:\n",
      "  Name: Prestigio SmartBook 133S Gold...\n",
      "  Price: $299\n",
      "  Rating: 4\n",
      "\n",
      "Product 4:\n",
      "  Name: Aspire E1-510...\n",
      "  Price: $306.99\n",
      "  Rating: 3\n",
      "\n",
      "Product 5:\n",
      "  Name: Lenovo V110-15IAP...\n",
      "  Price: $321.94\n",
      "  Rating: 3\n",
      "\n",
      "âœ“ Successfully extracted 117 records\n",
      "âœ“ Attributes collected: ['product_name', 'price', 'description', 'rating', 'reviews', 'extraction_date']\n",
      "âœ“ Raw data saved to output/raw_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>extraction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus VivoBook X441NA-GA190</td>\n",
       "      <td>$295.99</td>\n",
       "      <td>Asus VivoBook X441NA-GA190 Chocolate Black, 14...</td>\n",
       "      <td>3</td>\n",
       "      <td>14 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prestigio SmartBook 133S Dark Grey</td>\n",
       "      <td>$299</td>\n",
       "      <td>Prestigio SmartBook 133S Dark Grey, 13.3\" FHD ...</td>\n",
       "      <td>2</td>\n",
       "      <td>8 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestigio SmartBook 133S Gold</td>\n",
       "      <td>$299</td>\n",
       "      <td>Prestigio SmartBook 133S Gold, 13.3\" FHD IPS, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>12 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspire E1-510</td>\n",
       "      <td>$306.99</td>\n",
       "      <td>15.6\", Pentium N3520 2.16GHz, 4GB, 500GB, Linux</td>\n",
       "      <td>3</td>\n",
       "      <td>2 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo V110-15IAP</td>\n",
       "      <td>$321.94</td>\n",
       "      <td>Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1...</td>\n",
       "      <td>3</td>\n",
       "      <td>5 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lenovo Legion Y720</td>\n",
       "      <td>$1399</td>\n",
       "      <td>Lenovo Legion Y720, 15.6\" FHD IPS, Core i7-770...</td>\n",
       "      <td>3</td>\n",
       "      <td>8 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Asus ROG Strix GL702VM-GC146T</td>\n",
       "      <td>$1399</td>\n",
       "      <td>Asus ROG Strix GL702VM-GC146T, 17.3\" FHD, Core...</td>\n",
       "      <td>3</td>\n",
       "      <td>10 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Asus ROG Strix GL702ZC-GC154T</td>\n",
       "      <td>$1769</td>\n",
       "      <td>Asus ROG Strix GL702ZC-GC154T, 17.3\" FHD, Ryze...</td>\n",
       "      <td>4</td>\n",
       "      <td>7 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Asus ROG Strix GL702ZC-GC209T</td>\n",
       "      <td>$1769</td>\n",
       "      <td>Asus ROG Strix GL702ZC-GC209T, 17.3\" FHD IPS, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Asus ROG Strix SCAR Edition GL503VM-ED115T</td>\n",
       "      <td>$1799</td>\n",
       "      <td>Asus ROG Strix SCAR Edition GL503VM-ED115T, 15...</td>\n",
       "      <td>3</td>\n",
       "      <td>8 reviews</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   product_name    price  \\\n",
       "0                    Asus VivoBook X441NA-GA190  $295.99   \n",
       "1            Prestigio SmartBook 133S Dark Grey     $299   \n",
       "2                 Prestigio SmartBook 133S Gold     $299   \n",
       "3                                 Aspire E1-510  $306.99   \n",
       "4                             Lenovo V110-15IAP  $321.94   \n",
       "..                                          ...      ...   \n",
       "112                          Lenovo Legion Y720    $1399   \n",
       "113               Asus ROG Strix GL702VM-GC146T    $1399   \n",
       "114               Asus ROG Strix GL702ZC-GC154T    $1769   \n",
       "115               Asus ROG Strix GL702ZC-GC209T    $1769   \n",
       "116  Asus ROG Strix SCAR Edition GL503VM-ED115T    $1799   \n",
       "\n",
       "                                           description rating     reviews  \\\n",
       "0    Asus VivoBook X441NA-GA190 Chocolate Black, 14...      3  14 reviews   \n",
       "1    Prestigio SmartBook 133S Dark Grey, 13.3\" FHD ...      2   8 reviews   \n",
       "2    Prestigio SmartBook 133S Gold, 13.3\" FHD IPS, ...      4  12 reviews   \n",
       "3      15.6\", Pentium N3520 2.16GHz, 4GB, 500GB, Linux      3   2 reviews   \n",
       "4    Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1...      3   5 reviews   \n",
       "..                                                 ...    ...         ...   \n",
       "112  Lenovo Legion Y720, 15.6\" FHD IPS, Core i7-770...      3   8 reviews   \n",
       "113  Asus ROG Strix GL702VM-GC146T, 17.3\" FHD, Core...      3  10 reviews   \n",
       "114  Asus ROG Strix GL702ZC-GC154T, 17.3\" FHD, Ryze...      4   7 reviews   \n",
       "115  Asus ROG Strix GL702ZC-GC209T, 17.3\" FHD IPS, ...      1   8 reviews   \n",
       "116  Asus ROG Strix SCAR Edition GL503VM-ED115T, 15...      3   8 reviews   \n",
       "\n",
       "         extraction_date  \n",
       "0    2026-01-13 19:20:48  \n",
       "1    2026-01-13 19:20:48  \n",
       "2    2026-01-13 19:20:48  \n",
       "3    2026-01-13 19:20:48  \n",
       "4    2026-01-13 19:20:48  \n",
       "..                   ...  \n",
       "112  2026-01-13 19:20:48  \n",
       "113  2026-01-13 19:20:48  \n",
       "114  2026-01-13 19:20:48  \n",
       "115  2026-01-13 19:20:48  \n",
       "116  2026-01-13 19:20:48  \n",
       "\n",
       "[117 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etl.extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7aae1",
   "metadata": {},
   "source": [
    "### 3.3 Clean & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8be2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRANSFORMATION PHASE: Cleaning and transforming data\n",
      "============================================================\n",
      "\n",
      "Initial dataset shape: (117, 6)\n",
      "Initial missing values:\n",
      "product_name       0\n",
      "price              0\n",
      "description        0\n",
      "rating             0\n",
      "reviews            0\n",
      "extraction_date    0\n",
      "dtype: int64\n",
      "\n",
      "1. Removing duplicate records...\n",
      "   âœ“ Removed 1 duplicate records\n",
      "\n",
      "2. Handling missing values...\n",
      "   âœ“ Filled missing values\n",
      "\n",
      "3. Standardizing price format...\n",
      "   âœ“ Converted prices to numeric format\n",
      "   Price range: $295.99 - $1799.00\n",
      "\n",
      "4. Extracting brand information...\n",
      "   âœ“ Extracted 16 unique brands\n",
      "   Brands found: Asus, Prestigio, Aspire, Lenovo, Hewlett, Acer, Packard, Dell, HP, Pavilion, ProBook, Inspiron, ThinkPad, MSI, Toshiba, Apple\n",
      "\n",
      "5. Normalizing rating values...\n",
      "   âœ“ Converted ratings to numeric format\n",
      "   Rating range: 1.0 - 4.0\n",
      "\n",
      "6. Cleaning review counts...\n",
      "   âœ“ Extracted numeric review counts\n",
      "   Total reviews: 798\n",
      "\n",
      "âœ“ Data cleaning completed!\n",
      "Final dataset shape: (116, 7)\n",
      "\n",
      "Cleaned Dataset Summary:\n",
      "       Price (USD)      Rating  Review Count\n",
      "count   116.000000  116.000000    116.000000\n",
      "mean    907.759310    2.353448      6.879310\n",
      "std     402.661144    1.105357      4.269518\n",
      "min     295.990000    1.000000      0.000000\n",
      "25%     468.965000    1.000000      3.000000\n",
      "50%    1106.400000    2.000000      7.000000\n",
      "75%    1222.182500    3.000000     10.000000\n",
      "max    1799.000000    4.000000     14.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price (USD)</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Count</th>\n",
       "      <th>Description</th>\n",
       "      <th>Extraction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus VivoBook X441NA-GA190</td>\n",
       "      <td>Asus</td>\n",
       "      <td>295.99</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Asus VivoBook X441NA-GA190 Chocolate Black, 14...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prestigio SmartBook 133S Dark Grey</td>\n",
       "      <td>Prestigio</td>\n",
       "      <td>299.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Prestigio SmartBook 133S Dark Grey, 13.3\" FHD ...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestigio SmartBook 133S Gold</td>\n",
       "      <td>Prestigio</td>\n",
       "      <td>299.00</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Prestigio SmartBook 133S Gold, 13.3\" FHD IPS, ...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspire E1-510</td>\n",
       "      <td>Aspire</td>\n",
       "      <td>306.99</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.6\", Pentium N3520 2.16GHz, 4GB, 500GB, Linux</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo V110-15IAP</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>321.94</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lenovo Legion Y720</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>1399.00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>Lenovo Legion Y720, 15.6\" FHD IPS, Core i7-770...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Asus ROG Strix GL702VM-GC146T</td>\n",
       "      <td>Asus</td>\n",
       "      <td>1399.00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Asus ROG Strix GL702VM-GC146T, 17.3\" FHD, Core...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Asus ROG Strix GL702ZC-GC154T</td>\n",
       "      <td>Asus</td>\n",
       "      <td>1769.00</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Asus ROG Strix GL702ZC-GC154T, 17.3\" FHD, Ryze...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Asus ROG Strix GL702ZC-GC209T</td>\n",
       "      <td>Asus</td>\n",
       "      <td>1769.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Asus ROG Strix GL702ZC-GC209T, 17.3\" FHD IPS, ...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Asus ROG Strix SCAR Edition GL503VM-ED115T</td>\n",
       "      <td>Asus</td>\n",
       "      <td>1799.00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>Asus ROG Strix SCAR Edition GL503VM-ED115T, 15...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Product Name      Brand  Price (USD)  \\\n",
       "0                    Asus VivoBook X441NA-GA190       Asus       295.99   \n",
       "1            Prestigio SmartBook 133S Dark Grey  Prestigio       299.00   \n",
       "2                 Prestigio SmartBook 133S Gold  Prestigio       299.00   \n",
       "3                                 Aspire E1-510     Aspire       306.99   \n",
       "4                             Lenovo V110-15IAP     Lenovo       321.94   \n",
       "..                                          ...        ...          ...   \n",
       "112                          Lenovo Legion Y720     Lenovo      1399.00   \n",
       "113               Asus ROG Strix GL702VM-GC146T       Asus      1399.00   \n",
       "114               Asus ROG Strix GL702ZC-GC154T       Asus      1769.00   \n",
       "115               Asus ROG Strix GL702ZC-GC209T       Asus      1769.00   \n",
       "116  Asus ROG Strix SCAR Edition GL503VM-ED115T       Asus      1799.00   \n",
       "\n",
       "     Rating  Review Count                                        Description  \\\n",
       "0         3            14  Asus VivoBook X441NA-GA190 Chocolate Black, 14...   \n",
       "1         2             8  Prestigio SmartBook 133S Dark Grey, 13.3\" FHD ...   \n",
       "2         4            12  Prestigio SmartBook 133S Gold, 13.3\" FHD IPS, ...   \n",
       "3         3             2    15.6\", Pentium N3520 2.16GHz, 4GB, 500GB, Linux   \n",
       "4         3             5  Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1...   \n",
       "..      ...           ...                                                ...   \n",
       "112       3             8  Lenovo Legion Y720, 15.6\" FHD IPS, Core i7-770...   \n",
       "113       3            10  Asus ROG Strix GL702VM-GC146T, 17.3\" FHD, Core...   \n",
       "114       4             7  Asus ROG Strix GL702ZC-GC154T, 17.3\" FHD, Ryze...   \n",
       "115       1             8  Asus ROG Strix GL702ZC-GC209T, 17.3\" FHD IPS, ...   \n",
       "116       3             8  Asus ROG Strix SCAR Edition GL503VM-ED115T, 15...   \n",
       "\n",
       "         Extraction Date  \n",
       "0    2026-01-13 19:20:48  \n",
       "1    2026-01-13 19:20:48  \n",
       "2    2026-01-13 19:20:48  \n",
       "3    2026-01-13 19:20:48  \n",
       "4    2026-01-13 19:20:48  \n",
       "..                   ...  \n",
       "112  2026-01-13 19:20:48  \n",
       "113  2026-01-13 19:20:48  \n",
       "114  2026-01-13 19:20:48  \n",
       "115  2026-01-13 19:20:48  \n",
       "116  2026-01-13 19:20:48  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etl.clean_and_transform_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f03f9",
   "metadata": {},
   "source": [
    "### 3.4 Visualize Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48222ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VISUALIZATION: Creating before/after comparison charts\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ymyex\\AppData\\Local\\Temp\\ipykernel_23512\\3266026739.py:237: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  ax1.set_ylim(0, max(missing_before, missing_after) * 1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved cleaning comparison visualization to output/data_cleaning_comparison.png\n"
     ]
    }
   ],
   "source": [
    "etl.visualize_cleaning_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e56b3",
   "metadata": {},
   "source": [
    "### 3.5 Load to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4168d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING PHASE: Saving cleaned data\n",
      "============================================================\n",
      "âœ“ Cleaned data saved successfully!\n",
      "âœ“ File: output/laptops_clean_data.csv\n",
      "âœ“ Records: 116\n",
      "âœ“ Columns: ['Product Name', 'Brand', 'Price (USD)', 'Rating', 'Review Count', 'Description', 'Extraction Date']\n",
      "âœ“ File size: 17.95 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etl.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816731e",
   "metadata": {},
   "source": [
    "### 3.6 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2ad0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Dataset Overview:\n",
      "   Total Products: 116\n",
      "   Unique Brands: 16\n",
      "   Price Range: $295.99 - $1799.00\n",
      "   Average Price: $907.76\n",
      "   Average Rating: 2.35/5\n",
      "\n",
      "ðŸ“ˆ Brand Distribution:\n",
      "   Acer: 25 products (21.6%)\n",
      "   Lenovo: 20 products (17.2%)\n",
      "   Dell: 20 products (17.2%)\n",
      "   Asus: 19 products (16.4%)\n",
      "   MSI: 6 products (5.2%)\n",
      "   ThinkPad: 5 products (4.3%)\n",
      "   Toshiba: 5 products (4.3%)\n",
      "   Hewlett: 3 products (2.6%)\n",
      "   Apple: 3 products (2.6%)\n",
      "   Prestigio: 2 products (1.7%)\n",
      "   Aspire: 2 products (1.7%)\n",
      "   HP: 2 products (1.7%)\n",
      "   Packard: 1 products (0.9%)\n",
      "   Pavilion: 1 products (0.9%)\n",
      "   ProBook: 1 products (0.9%)\n",
      "   Inspiron: 1 products (0.9%)\n",
      "\n",
      "ðŸ’° Price Statistics by Brand:\n",
      "                  mean      min      max\n",
      "Brand                                   \n",
      "Acer        636.842000   372.70  1221.58\n",
      "Apple      1313.636667  1260.13  1347.78\n",
      "Aspire      444.490000   306.99   581.99\n",
      "Asus        996.141579   295.99  1799.00\n",
      "Dell       1107.547000   488.78  1341.22\n",
      "HP          549.490000   520.99   577.99\n",
      "Hewlett     988.133333   364.46  1326.83\n",
      "Inspiron    745.990000   745.99   745.99\n",
      "Lenovo      852.308000   321.94  1399.00\n",
      "MSI        1187.333333  1099.00  1299.00\n",
      "Packard     416.990000   416.99   416.99\n",
      "Pavilion    609.990000   609.99   609.99\n",
      "Prestigio   299.000000   299.00   299.00\n",
      "ProBook     739.990000   739.99   739.99\n",
      "ThinkPad   1198.790000  1033.99  1311.99\n",
      "Toshiba    1226.612000  1114.55  1366.32\n"
     ]
    }
   ],
   "source": [
    "etl.generate_summary_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66da2c",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07437b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 116, Columns: ['Product Name', 'Brand', 'Price (USD)', 'Rating', 'Review Count', 'Description', 'Extraction Date']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price (USD)</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Count</th>\n",
       "      <th>Description</th>\n",
       "      <th>Extraction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus VivoBook X441NA-GA190</td>\n",
       "      <td>Asus</td>\n",
       "      <td>295.99</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Asus VivoBook X441NA-GA190 Chocolate Black, 14...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prestigio SmartBook 133S Dark Grey</td>\n",
       "      <td>Prestigio</td>\n",
       "      <td>299.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Prestigio SmartBook 133S Dark Grey, 13.3\" FHD ...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestigio SmartBook 133S Gold</td>\n",
       "      <td>Prestigio</td>\n",
       "      <td>299.00</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Prestigio SmartBook 133S Gold, 13.3\" FHD IPS, ...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspire E1-510</td>\n",
       "      <td>Aspire</td>\n",
       "      <td>306.99</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.6\", Pentium N3520 2.16GHz, 4GB, 500GB, Linux</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo V110-15IAP</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>321.94</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1...</td>\n",
       "      <td>2026-01-13 19:20:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Product Name      Brand  Price (USD)  Rating  \\\n",
       "0          Asus VivoBook X441NA-GA190       Asus       295.99       3   \n",
       "1  Prestigio SmartBook 133S Dark Grey  Prestigio       299.00       2   \n",
       "2       Prestigio SmartBook 133S Gold  Prestigio       299.00       4   \n",
       "3                       Aspire E1-510     Aspire       306.99       3   \n",
       "4                   Lenovo V110-15IAP     Lenovo       321.94       3   \n",
       "\n",
       "   Review Count                                        Description  \\\n",
       "0            14  Asus VivoBook X441NA-GA190 Chocolate Black, 14...   \n",
       "1             8  Prestigio SmartBook 133S Dark Grey, 13.3\" FHD ...   \n",
       "2            12  Prestigio SmartBook 133S Gold, 13.3\" FHD IPS, ...   \n",
       "3             2    15.6\", Pentium N3520 2.16GHz, 4GB, 500GB, Linux   \n",
       "4             5  Lenovo V110-15IAP, 15.6\" HD, Celeron N3350 1.1...   \n",
       "\n",
       "       Extraction Date  \n",
       "0  2026-01-13 19:20:48  \n",
       "1  2026-01-13 19:20:48  \n",
       "2  2026-01-13 19:20:48  \n",
       "3  2026-01-13 19:20:48  \n",
       "4  2026-01-13 19:20:48  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('output/laptops_clean_data.csv')\n",
    "print(f\"Records: {len(df)}, Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cb9c2",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ“ ETL Complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
